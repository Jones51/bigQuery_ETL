# AutomaÃ§Ã£o de Pipeline de Dados (ETL)

## ğŸ› ï¸ IntroduÃ§Ã£o 
Projeto com o intuito de criar um pipeline de dados automatizados, desde o consumo dos dados, sua transformaÃ§Ã£o e carregamento em diferentes tipos de banco de dados (PostgreSQL, MongoDB e BigQuery), a fim de estudar suas estruturas e particularidades de conexÃ£o.

## ğŸ“ Problema de NegÃ³cios 
Muitas vezes o processo de consumo de dados pode ser moroso, com dados extraÃ­dos direto de um portal, necessitando de intervenÃ§Ã£o humana ou mesmo de processos lentos. O projeto se propÃµe a automatizar todo o processo, usando as boas prÃ¡ticas e ferramentas no mercado de referÃªncia.

## ğŸ“ Metodologia 
1. Consumo dos dados da API.
2. Tratamento dos dados em Python.
4. ConfiguraÃ§Ã£o e carregamento dos dados em banco PostgreSQL.
5. ConfiguraÃ§Ã£o e carregamento dos dados em banco MongoDB.
6. ConfiguraÃ§Ã£o e carregamento dos dados em banco BigQuery.

## ğŸ“Š Habilidades 
-Python: Jupyter notebook, Pandas, TransformaÃ§Ã£o dos dados, ETL, APIs (request)
-Banco de dados: Google BigQuery, PostgreSQL, MongoDB

## ğŸª„ Projeto Final 
<img width="1308" height="179" alt="image" src="https://github.com/user-attachments/assets/68bb4e06-7534-4264-b944-90d5ebd043f6" />

<img width="1428" height="903" alt="image" src="https://github.com/user-attachments/assets/f5a27e62-5535-4e8f-92f6-9caf105a925f" />

<img width="1509" height="815" alt="image" src="https://github.com/user-attachments/assets/6673bdae-3eb5-4df7-a38f-fdf6dd5749c6" />

<img width="1552" height="824" alt="image" src="https://github.com/user-attachments/assets/bce0116d-4c02-4c38-bd52-0dd07c0bf96d" />

<img width="1524" height="826" alt="image" src="https://github.com/user-attachments/assets/568b3bff-be8c-4c63-b72b-c854c3c3e25a" />












